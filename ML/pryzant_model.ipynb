{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pryzant_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCWuDTV8lOYg"
      },
      "source": [
        "# Imports and Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OQGJL7mGeth",
        "outputId": "ea783b1c-38cc-486c-8cca-de6e8e7678a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install pytorch-pretrained-bert\n",
        "!pip3 install simplediff\n",
        "!pip3 install tensorboardX"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.9)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.6.0+cu101)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.9 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.19.9)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.9->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.9->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: simplediff in /usr/local/lib/python3.6/dist-packages (1.0)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScTU41vvPPO3"
      },
      "source": [
        "#from pytorch_pretrained_bert.modeling import PreTrainedBertModel, BertModel, BertSelfAttention\n",
        "import pytorch_pretrained_bert.modeling as modeling\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "from pytorch_pretrained_bert.modeling import BertForTokenClassification\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tensorboardX import SummaryWriter\n",
        "import argparse\n",
        "import sklearn.metrics as metrics"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AP37WF_N2A8"
      },
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "from pytorch_pretrained_bert.modeling import BertModel, BertSelfAttention\n",
        "from pytorch_pretrained_bert.modeling import BertPreTrainedModel"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoQGZRQAJ6Xj"
      },
      "source": [
        "#from shared.args import ARGS \n",
        "#from shared.constants import CUDA \n",
        "#import seq2seq.model as seq2seq_model\n",
        "CUDA = (torch.cuda.device_count() > 0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFt_ZGseLQ6A"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO9jTo8oRRtJ"
      },
      "source": [
        "## Update the experiments directory\n",
        "DATA_DIRECTORY = '/content/drive/Shared drives/EC463 464 Senior Design Project/data/'\n",
        "LEXICON_DIRECTORY = DATA_DIRECTORY+ 'lexicons/'\n",
        "PRYZANT_DATA = DATA_DIRECTORY + 'pryzant_data/WNC/'\n",
        "#IMPORTS = \n",
        "training_data = PRYZANT_DATA + 'biased.word.train'\n",
        "testing_data = PRYZANT_DATA + 'biased.word.test'\n",
        "categories_file = PRYZANT_DATA + 'revision_topics.csv'\n",
        "pickle_directory = '/content/drive/Shared drives/EC463 464 Senior Design Project/data/pickle_data/'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmyALBDnX7fl"
      },
      "source": [
        "# Load imports\n",
        "!cp '/content/drive/Shared drives/EC463 464 Senior Design Project/imports/data.py' .\n",
        "import data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjeba1jjaol3",
        "outputId": "efcf8aa9-3e4d-4045-ae77-6fffc945bc9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4upcahxZXBv",
        "outputId": "f8aa789e-76db-4035-f9ce-b0553c378ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('LOADING DATA...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', os.getcwd() + '/cache')\n",
        "tok2id = tokenizer.vocab\n",
        "tok2id['<del>'] = len(tok2id)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOADING DATA...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 1158820.30B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tbgzf4_bY7F",
        "outputId": "58ede2e4-6210-4786-b57d-f93e8e4d05eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataloader, num_train_examples = data.get_dataloader(\n",
        "    data_path=training_data,\n",
        "    tok2id=tok2id,\n",
        "    batch_size=32,\n",
        "    pickle_path=pickle_directory + 'train_data.p',\n",
        "    categories_path=categories_file\n",
        "  )\n",
        "\n",
        "eval_dataloader, num_eval_examples = data.get_dataloader(\n",
        "    data_path=testing_data,\n",
        "    tok2id=tok2id,\n",
        "    batch_size=32,\n",
        "    pickle_path=pickle_directory + 'test_data.p',\n",
        "    categories_path=categories_file\n",
        "  )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53803it [00:11, 4818.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SKIPPED  1503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1000it [00:01, 970.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SKIPPED  32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9zskQmmeVnp",
        "outputId": "84147f22-97dd-4a4c-b9d1-4e1900dd19dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "for step, x in enumerate(train_dataloader):\n",
        "  #print(x.size())\n",
        "  print(x)\n",
        "  print(x[0])\n",
        "  print(x[0][0])\n",
        "  \n",
        "  input()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-b4bf2bb33b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnNtPufYk8QV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1hNyN2KlVWJ"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11a9sxzIlUvA"
      },
      "source": [
        "class BertForMultitask(BertPreTrainedModel):\n",
        "\n",
        "    def __init__(self, config, cls_num_labels=2, tok_num_labels=2, tok2id=None):\n",
        "        super(BertForMultitask, self).__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "\n",
        "        self.cls_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.cls_classifier = nn.Linear(config.hidden_size, cls_num_labels)\n",
        "        \n",
        "        self.tok_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.tok_classifier = nn.Linear(config.hidden_size, tok_num_labels)\n",
        "        \n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, \n",
        "        labels=None, rel_ids=None, pos_ids=None, categories=None, pre_len=None):\n",
        "        global ARGS\n",
        "        sequence_output, pooled_output = self.bert(\n",
        "            input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "\n",
        "        cls_logits = self.cls_classifier(pooled_output)\n",
        "        cls_logits = self.cls_dropout(cls_logits)\n",
        "\n",
        "        # NOTE -- dropout is after proj, which is non-standard\n",
        "        tok_logits = self.tok_classifier(sequence_output)\n",
        "        tok_logits = self.tok_dropout(tok_logits)\n",
        "\n",
        "        return cls_logits, tok_logits"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zFf9kQMnuiR"
      },
      "source": [
        "class TaggerFromDebiaser(nn.Module):\n",
        "    def __init__(self, cls_num_labels=2, tok_num_labels=2, hidden_size=512, tok2id=None):\n",
        "        super(TaggerFromDebiaser, self).__init__()\n",
        "\n",
        "        #global ARGS\n",
        "        #global CUDA\n",
        "\n",
        "        #if ARGS.pointer_generator:\n",
        "        #    self.debias_model = seq2seq_model.PointerSeq2Seq(\n",
        "        #        vocab_size=len(tok2id), hidden_size=hidden_size,\n",
        "        #        emb_dim=768, dropout=0.2, tok2id=tok2id)\n",
        "        #else:\n",
        "        # GET THE SEQ2SEQ MODEL!!!!\n",
        "        self.debias_model = seq2seq_model.Seq2Seq(\n",
        "            vocab_size=len(tok2id), hidden_size=hidden_size,\n",
        "            emb_dim=768, dropout=0.2, tok2id=tok2id)\n",
        "\n",
        "        #assert ARGS.debias_checkpoint\n",
        "        #print('LOADING DEBIASER FROM ' + ARGS.debias_checkpoint)\n",
        "        #self.debias_model.load_state_dict(torch.load(ARGS.debias_checkpoint))\n",
        "        #print('...DONE')\n",
        "\n",
        "        self.cls_classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, cls_num_labels),\n",
        "            nn.Dropout(0.1))\n",
        "\n",
        "        self.tok_classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, tok_num_labels),\n",
        "            nn.Dropout(0.1))\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None,\n",
        "        labels=None, rel_ids=None, pos_ids=None, categories=None, pre_len=None):\n",
        "\n",
        "        pre_mask = 1.0-attention_mask\n",
        "\n",
        "        # src_outputs is [batch_size, sequence_length, hidden_size].\n",
        "        src_outputs, h_t, _ = self.debias_model.run_encoder(\n",
        "            input_ids, pre_len, pre_mask)\n",
        "\n",
        "        cls_logits = self.cls_classifier(h_t)\n",
        "        tok_logits = self.tok_classifier(src_outputs)\n",
        "\n",
        "        return cls_logits, tok_logits"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdN7lAcBoTl8",
        "outputId": "e920e606-eecd-47cf-a2fe-3ba651504167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        }
      },
      "source": [
        "model = TaggerFromDebiaser(\n",
        "        cls_num_labels=43, tok_num_labels=3,\n",
        "        tok2id=tok2id)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-7f0c8b090de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = TaggerFromDebiaser(\n\u001b[1;32m      2\u001b[0m         \u001b[0mcls_num_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok_num_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         tok2id=tok2id)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-75f8c4037b4f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cls_num_labels, tok_num_labels, hidden_size, tok2id)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#        emb_dim=768, dropout=0.2, tok2id=tok2id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         self.debias_model = seq2seq_model.Seq2Seq(\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             emb_dim=768, dropout=0.2, tok2id=tok2id)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seq2seq_model' is not defined"
          ]
        }
      ]
    }
  ]
}